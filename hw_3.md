# Project Abstact

- Team members
  - me
  - Chris Cook (special permission from Tyler to work with someone outside of class)
  
## Problem Statement
Historical economics currently uses string fuzzy matching techniques to link records together. Current practices use
some measure of string distance like Jaro-Winkler or SOUNDEX. However, these tools do not fully represent the true
distance of names from each other because nicknames can sometimes look nothing like the full name. We propose using
machine learning techniques to create a distance metric or name vector space that accurately represents the similarity of names.

## Data
We will use FamilySearch data to approach the problem. We currently have data on links between censuses generated by users
on FamilySearch. This also creates links between names in the census that can be used to show which names are the same.

### Data Cleaning
We will concentrate data cleaning mainly on organizing the dataset for the models that we will use. We will take names from each of the censuses and merge them with the names they were linked to in the other censuses, saving important statistics like gender, race, number of links, etc. If any demographic variables are missing, we could potentially use the other people with the same name to fill in the missing values.

In terms of outliers, we should not toss any that have too many links. These observations will be names like John and Mary that represent a large proportion of the population. However, there will likely be many names that do not have links to other names. These will serve very little purpose for developing our model, but we can use them as tests to see if we can introduce unconnected names to our model and get accurate matches in return. There will also be many names that have few links to others. Dropping these names would be a mistake since we want our model to be robust to uncommon names.

In the end, we will have a dataset that will consist of a two linked names, the number of links between them, and demographic statistics of each of the names.

## Analysis
A simple approach is to say that any names linked between censuses are the same. However, noise in the data complicates this
since people often switch between their middle and first names or go by nicknames that have nothing to do with the actual name.
Therefore, we will use numerous tools to deal with this.

### Network Analysis
A method for blocking names is to use community structure analysis on the implicit network in the FamilySearch data. 
If we treat each name as a node in a graph and links in the census as weighted edges, we obtain a network. If two names
are similar, they should have a dense edge between them and share links to other names that are similar. Using community
structure techniques--like modularity maximization and statistical inference--we can identify communities of names that are similar enough to be considered the same.

These models often only care about the communities. Hence, these models are much better at grouping the data into clusters than actually creating distance measures comparable to other string comparisons. However, there are some models that we could possibly adapt to give us some type of similarity score between the names based on the likelihood that they end up in the same community. However, grouping the names can provide us with common mispellings. If two names differ by a character and are in the same community, it's likely that the character was either written incorrectly by the enumerator of the census or that the indexer failed to read the character correctly. We can use this information to obtain similarity scores for characters or create character vectors much like the word vectors discussed below. 

### K nearest neighbors
Another simple process is to identify distance between names using K nearest neighbors. We can measure the distance between names using gender, race, links, already known distance measures, etc. to obtain the distance of names to each other. One large issue will be computing power. We have millions of names in our sample, so comparing all of them pairwise is challenging problem. Because of the simplicity of the model, K nearest neighbors can act as a baseline for other models.

### Creating Word Vectors in a Name Space
Words vectors are numerical representations of strings along several dimensions. Example dimensions in a name space could
include the gender of the name, the origin of the name, similarity of characters, etc. Word vectors are often used in NLP for interpreting the meaning of words instead of only comparing characters in a string. This will be perfect for name analysis since nicknames can be completely different from the original name (like Richard and Dick). In order to compute word vectors, other researchers use neural net packages like Tensorflow or some custom neural net models like word2vec. Once we have the word vectors, we can use cosine similarity scores or other distance metrics to obtain the same results as the previous models.

### Combining Models
Since each model offers unique insights to the similarity of names, stacking our models will address weaknesses in each model while keeping their strengths. When we do this, we can use older approaches to fuzzy matching like Soundex and Jaro-Winkler scores as well to see if they fill in gaps in our newer models.

## Related Materials

[Tensorflow: Vector Representations of Words](https://www.tensorflow.org/tutorials/representation/word2vec)
[Soundex](https://en.wikipedia.org/wiki/Soundex)
[Jaro-Winkler Distance](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance)
[Modularity Maximization](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1482622/)
[Other Community Detection Methods](https://en.wikipedia.org/wiki/Community_structure)
[Comparison of Name Matching Algorithms](https://www.researchgate.net/profile/Chakkrit_Snae/publication/242594357_A_Comparison_and_Analysis_of_Name_Matching_Algorithms/links/004635330fb777dff9000000.pdf)

